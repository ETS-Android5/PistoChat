{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PistoChat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1iRUzufHSh",
        "outputId": "5c880269-4b5f-4654-d02d-eff0cda3ea70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 23 22:39:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/pistocop/messaging-chat-parser.git\n",
        "!pip install -q -r messaging-chat-parser/requirements.txt\n",
        "!pip install aitextgen\n",
        "!git clone --quiet https://github.com/pistocop/pistoBot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V89s7NYNfILZ",
        "outputId": "04edf985-6014-4861-c810-09017eff565a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aitextgen\n",
            "  Downloading aitextgen-0.5.2.tar.gz (572 kB)\n",
            "\u001b[K     |████████████████████████████████| 572 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.5.1\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 41.2 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning>=1.3.1\n",
            "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.10.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.21.6)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.8.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 47.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.6 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.8)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.2.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.9 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 16.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.1.0)\n",
            "Building wheels for collected packages: aitextgen, fire\n",
            "  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=fa82e255994a3fa78b2da3a4275821f120eeee4069f3f9f4454c88205852a42e\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=d720b1fe00fd29fd7a0dd5d828b3a3682d0033d141daf0b8ce5fcad1508fc11b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built aitextgen fire\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, pyDeprecate, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, huggingface-hub, transformers, pytorch-lightning, fire, aitextgen\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 aitextgen-0.5.2 async-timeout-4.0.2 asynctest-0.13.0 fire-0.4.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 sacremoses-0.0.49 tokenizers-0.12.1 torchmetrics-0.8.0 transformers-4.18.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW0lh_dzdwxQ",
        "outputId": "97f8285e-097c-470a-f09d-33725baa6e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from pprint import pprint\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "import threading\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "# Use the application default credentials\n",
        "cred = credentials.Certificate(\"./serviceAccountKey.json\")\n",
        "firebase_admin.initialize_app(cred)\n",
        "\n",
        "db = firestore.client()\n",
        "collection = db.collection('users').stream() \n",
        "\n",
        "count = 0\n",
        "\n",
        "class Chat:\n",
        "    def __init__(self, id, autoChat, chatBotMode, date, freq, export):\n",
        "        self.autoChat = autoChat\n",
        "        self.chatBotMode = chatBotMode\n",
        "        self.lastUpdate = date\n",
        "        self.frequency = freq\n",
        "        self.id = id\n",
        "        self.export = export\n",
        "\n",
        "class User:\n",
        "  def __init__(self, id):\n",
        "    self.convos = []\n",
        "    self.id = id\n",
        "\n",
        "def getUsers():\n",
        "    users = []\n",
        "    collection = db.collection('users').stream() \n",
        "    for doc in collection:\n",
        "        user = User(doc.id)\n",
        "        chats = db.collection(doc.id).stream()\n",
        "        for chat in chats:            \n",
        "            temp = chat.to_dict()\n",
        "            print(temp)\n",
        "            convo = Chat(chat.id, temp['autoChat'], temp['chatBotMode'], temp['lastUpdate'], temp['frequency'], temp['export'])\n",
        "            user.convos.append(convo)\n",
        "        users.append(user)\n",
        "    return users\n",
        "\n",
        "\n",
        "# def getConvos():\n",
        "#     print()\n",
        "\n",
        "def getUserNameById(id):\n",
        "    doc_ref = db.collection('users').stream()\n",
        "    for doc in doc_ref:\n",
        "        if doc.id == id:\n",
        "          temp = doc.to_dict()\n",
        "          return temp['name']\n",
        "\n",
        "def parseChats(userId, convoId):\n",
        "    text_file = open(\"./messaging-chat-parser/data/chat_raw/whatsapp/\"+userId+convoId+\".txt\", \"w\")\n",
        "    doc_ref = db.collection(userId).stream()\n",
        "    for doc in doc_ref:\n",
        "        if doc.id == convoId:\n",
        "            temp = doc.to_dict()\n",
        "            text_file.write(temp['export'])\n",
        "            text_file.close()\n",
        "            tmp = getUserNameById(userId)\n",
        "            l = tmp.split()\n",
        "            user_name = \"\"\n",
        "            for item in l:\n",
        "              user_name+=\"\\ \"+item\n",
        "\n",
        "            datetime_format = \"%m/%d/%y,\\ %H:%M\"\n",
        "            print(\"> start parsing...\")\n",
        "            assert user_name is not None, \"[!] User name not available\"\n",
        "            cmd = \"cd messaging-chat-parser && python ./src/whatsapp_parser.py --session_token \"+ \"\\\"<|endoftext|>\\\"\" + \" --user_name \" + user_name + \" --time_format \" + datetime_format+\" && \" + \"mv ./data/chat_parsed/wa-chats.txt ./data/chat_parsed/\"+userId+convoId+\".txt\"\n",
        "            print(cmd)\n",
        "            os.system(cmd)\n",
        "            print(\"----------------------------------\")\n",
        "\n",
        "# parseChats('9305021235', '9026663925')\n",
        "\n",
        "def trainModel(userId, convoId):\n",
        "    os.system(\"cp ./messaging-chat-parser/data/chat_parsed/models-trained\"+userId+convoId+\".txt \" + \"./pistoBot/data/inputs/chat_parsed/all-messages-endoftext.txt\")\n",
        "    os.system(\"cd pistoBot/colab/ && bash run_training.sh gpt2-scratch\")\n",
        "\n",
        "def loadModel():\n",
        "    files = os.listdir(\"./pistoBot/data/models-trained\")\n",
        "    folder_name = files[0]\n",
        "    \n",
        "    model_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models-trained\", folder_name)\n",
        "    config_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models-trained\", folder_name,\"config.json\")\n",
        "    vocab_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models-trained\", folder_name,\"aitextgen-vocab.json\")\n",
        "    merges_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models-trained\", folder_name,\"aitextgen-merges.txt\")\n",
        "\n",
        "    ai = aitextgen(model_folder=model_path, \n",
        "               config=config_path,\n",
        "               vocab_file=vocab_path,\n",
        "               merges_file=merges_path,\n",
        "               to_gpu=True)\n",
        "    return ai\n",
        "\n",
        "\n",
        "\n",
        "def addMsgToConvo(msg, senderNo, receiverNo):\n",
        "    doc_ref = db.collection('chats').document()\n",
        "    doc_ref.set({\n",
        "        'Message Type': 'text',\n",
        "        'message': msg,\n",
        "        'receiverNo': receiverNo+'x',\n",
        "        'senderNo': senderNo,\n",
        "        'time': firestore.SERVER_TIMESTAMP\n",
        "    })\n",
        "    print(doc_ref.id)\n",
        "\n",
        "# addMsgToConvo(\"0xCAFEBABE\", \"9305021235\", \"1234567890\")\n",
        "\n",
        "def getLastMsgFromConvo(userId, convoId):\n",
        "    doc_ref = db.collection(userId).stream()\n",
        "    for doc in doc_ref:\n",
        "      if doc.id == (convoId+'x'):\n",
        "        tmp = doc.to_dict()\n",
        "        return tmp['lastMessage']\n",
        "\n",
        "def chatBot(lastMessage, userId, convoId):\n",
        "  chat = []\n",
        "  start_temperature = 0.7\n",
        "  max_temperature = 3.0\n",
        "\n",
        "  for _ in range(5):\n",
        "      new_line = \"[others] \" + lastMessage + '\\n'\n",
        "      chat.append(new_line)\n",
        "      \n",
        "      me_token = False\n",
        "      temperature = start_temperature\n",
        "      input_network = ' '.join(chat)\n",
        "      \n",
        "      while not me_token:\n",
        "          ai = loadModel()\n",
        "          text = ai.generate(prompt=input_network, \n",
        "                            return_as_list=True, \n",
        "                            temperature=temperature)\n",
        "          text = text[0] # batch of 1\n",
        "\n",
        "          text = text.split('\\n')\n",
        "          print(text)\n",
        "          msg = text[2].split();\n",
        "          ans = \"\"\n",
        "          for i in range(len(msg)):\n",
        "            if i==0:\n",
        "              continue\n",
        "            ans = ans + msg[i] + \" \"\n",
        "          print(ans)\n",
        "          return ans\n",
        "\n",
        "print(chatBot(getLastMsgFromConvo('9305021235', '9026663925'), '9305021235', '9026663925'))\n",
        "    \n",
        "\n",
        "\n",
        "while True:\n",
        "    if count%1000000 == 0:\n",
        "        users = getUsers()\n",
        "        for user in users:\n",
        "            user.convos = getConvos()\n",
        "\n",
        "    if datetime.now().strftime(\"%H:%M:%S\") != \"00:00:00\":\n",
        "        count = count + 1\n",
        "        continue\n",
        "\n",
        "    for user in users:\n",
        "        for convo in user.convos:\n",
        "            if convo.autoChat and convo.lastUpdate+timedelta(days=convo.frequency) == date.today():\n",
        "                print(\"Model training of \"+convo.id+\" for \"+user.id)\n",
        "                t1 = threading.Thread(target=createModel, args=(convo.id,))\n",
        "                t1.start()\n",
        "            while convo.chatBotMode:\n",
        "                print(\"Conversation started between \"+user.id+\" and \"+convo.id)\n",
        "                t2 = threading.Thread(target=addMsgToConvo, args=((getLastMsgFromConvo(convo.id),))\n",
        "                t2.start()\n",
        "\n",
        "\n",
        "    count = count + 1\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI-U3q1vkASZ",
        "outputId": "122fc2ce-15ad-4bea-9564-190af154f6d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[others] hello', '', \"[others] Don't worry bro\", '', '[others] whu', '', '[others] why', '', '']\n",
            "Don'tworrybro\n",
            "Don'tworrybro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evozflYkfBX3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}